{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.0 Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from datetime import datetime\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.0 Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sales_group = pd.read_csv('dataset/sales_group.csv')\n",
    "\n",
    "author = pd.read_csv('dataset/author.csv')\n",
    "award = pd.read_csv('dataset/award.csv')\n",
    "book = pd.read_csv('dataset/book.csv')\n",
    "edition = pd.read_csv('dataset/edition.csv')\n",
    "format = pd.read_csv('dataset/format.csv')\n",
    "genders = pd.read_csv('dataset/genders.csv')\n",
    "info = pd.read_csv('dataset/info.csv')\n",
    "publisher = pd.read_csv('dataset/publisher.csv')\n",
    "ratings = pd.read_csv('dataset/ratings.csv')\n",
    "series = pd.read_csv('dataset/series.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Basic Data Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renaming the columns on the award dataset to eliminate spaces\n",
    "cols_new = ['book_id', 'title', 'award_name', 'year_won']\n",
    "award.columns = cols_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: author - Quantidade de duplicadas: 0\n",
      "\n",
      "Dataset: award - Quantidade de duplicadas: 0\n",
      "\n",
      "Dataset: book - Quantidade de duplicadas: 0\n",
      "\n",
      "Dataset: edition - Quantidade de duplicadas: 0\n",
      "\n",
      "Dataset: format - Quantidade de duplicadas: 0\n",
      "\n",
      "Dataset: info - Quantidade de duplicadas: 0\n",
      "\n",
      "Dataset: publisher - Quantidade de duplicadas: 119\n",
      "\n",
      "Dataset: series - Quantidade de duplicadas: 0\n",
      "\n",
      "Dataset: genders - Quantidade de duplicadas: 0\n",
      "\n",
      "Dataset: ratings - Quantidade de duplicadas: 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Checking for duplicates\n",
    "datasets = [author, award, book, edition, format, info, publisher, series, genders, ratings]\n",
    "datasets_names = ['author', 'award', 'book', 'edition', 'format', 'info', 'publisher', 'series', 'genders', 'ratings']\n",
    "\n",
    "i=0\n",
    "for dataset in datasets:\n",
    "    print(f'Dataset: {datasets_names[i]} - Quantidade de duplicadas: {dataset.duplicated().sum()}\\n')\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets remove the duplicates from the publisher dataset\n",
    "publisher.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Merging the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(book, author, how='left', on='author_id')\n",
    "df = pd.merge(df, info, how='left', on='book_id')\n",
    "df = pd.merge(df, series, how='left', on='series_id')\n",
    "df = pd.merge(df, genders, how='left', on='genre_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.1 Award dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The award dataset has duplicated book_ids for books with multiple awards, lets aggregate them before merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "award_agg = award.groupby('book_id').agg({\n",
    "    'title': 'first',\n",
    "    'award_name': lambda x: ', '.join(x),\n",
    "    'year_won': 'first'}).reset_index()\n",
    "\n",
    "df = pd.merge(df, award_agg, how='left', on='book_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.2 Publisher dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The publisher dataset also has duplicated book_ids for books with multiple publishers. But, we have a problem that some publishers have two different pub_ids, so we can't merge them yet.\n",
    "\n",
    "So, first we'll determine that the right pub_id is the one who corresponds to the initials of the publisher name.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining useful functions\n",
    "\n",
    "def get_initials(name):\n",
    "    return \"\".join(word[0] for word in name.split()).upper()\n",
    "\n",
    "def select_pub_id(group):\n",
    "    initials = group[\"initials\"].iloc[0]\n",
    "    matching_pub_id = group[group[\"pub_id\"] == initials]\n",
    "\n",
    "    if not matching_pub_id.empty:\n",
    "        return matching_pub_id.iloc[0]\n",
    "    else:\n",
    "        return group.sort_values(\"pub_id\").iloc[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the initials of the publisher name\n",
    "publisher[\"initials\"] = publisher[\"name\"].apply(get_initials)\n",
    "\n",
    "# Selecting the correct pub_id\n",
    "publisher_corrected = publisher.groupby([\"book_id\", \"name\"], group_keys=False).apply(select_pub_id)\n",
    "publisher_corrected.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Dropping the initial column\n",
    "publisher_corrected = publisher_corrected.drop(columns=[\"initials\"])\n",
    "publisher = publisher.drop(columns=[\"initials\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can aggregate and merge the datasets.\n",
    "\n",
    "Here, we'll opt for summing the marketing spend, since it's the corresponding value for each book"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregating the publisher dataset\n",
    "publisher_agg = publisher_corrected.groupby('book_id').agg({\n",
    "    'name': lambda x: ', '.join(x),\n",
    "    'city': lambda x: ', '.join(x),\n",
    "    'state': 'first',\n",
    "    'country': 'first',\n",
    "    'year_established': 'first',\n",
    "    'marketing_spend': 'sum',\n",
    "    'pub_id': lambda x: ', '.join(x)\n",
    "}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging the datasets\n",
    "df = pd.merge(df, publisher_agg, how='left', on='book_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.3 Ratings dataset\n",
    "\n",
    "Let's keep only the average rating and the number of ratings for each book"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the average rating\n",
    "ratings_mean = ratings.groupby('book_id')['rating'].mean().round(2).reset_index()\n",
    "ratings_mean.columns = ['book_id', 'rating_mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the number of ratings\n",
    "ratings_count = ratings.groupby('book_id')['rating'].count().reset_index()\n",
    "ratings_count.columns = ['book_id', 'rating_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging the datasets\n",
    "df = pd.merge(df, ratings_mean, how='left', on='book_id')\n",
    "df = pd.merge(df, ratings_count, how='left', on='book_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.4 Edition dataset\n",
    "\n",
    "Lets first merge the edition and the format datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_edition = pd.merge(edition, format, how='left', on='format_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_edition.drop(columns=['format_id'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.5 Sales dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales = pd.merge(df_sales_group, df_edition, how='left', on='isbn')\n",
    "# sales = pd.merge(sales, df, how='left', on=['book_id', 'pub_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.0 Data Transformation\n",
    "\n",
    "Lets organize the data before merging into the sales dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the author name\n",
    "df['author_name'] = df['first_name'] + ' ' + df['last_name']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Dataset columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove unuseful columns\n",
    "df.drop(columns=['title_y', 'author_id', 'genre_id', 'series_id', 'first_name', 'last_name'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renaming the columns\n",
    "df.rename(columns={\n",
    "    'title_x': 'title',\n",
    "    'genre_desc': 'genre',\n",
    "    'name': 'pub_name',\n",
    "    'city': 'pub_city',\n",
    "    'state': 'pub_state',\n",
    "    'country': 'pub_country'\n",
    "}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales.rename(columns={\n",
    "    'COUNT': 'sales_count',\n",
    "    'format_desc': 'format'\n",
    "}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "book_id                      object\n",
       "title                        object\n",
       "birthday             datetime64[ns]\n",
       "country_residence            object\n",
       "hrs_writing_day             float64\n",
       "volume_number                 Int64\n",
       "series_name                  object\n",
       "genre                        object\n",
       "award_name                   object\n",
       "year_won                      Int64\n",
       "pub_name                     object\n",
       "pub_city                     object\n",
       "pub_state                    object\n",
       "pub_country                  object\n",
       "year_established              Int64\n",
       "marketing_spend               Int64\n",
       "pub_id                       object\n",
       "rating_mean                 float64\n",
       "rating_count                  Int64\n",
       "author_name                  object\n",
       "dtype: object"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the data types\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sale_date           datetime64[ns]\n",
       "isbn                        object\n",
       "sales_count                  int64\n",
       "book_id                     object\n",
       "pub_id                      object\n",
       "publication_date    datetime64[ns]\n",
       "pages                        Int64\n",
       "print_run_size_k             Int64\n",
       "price                      float64\n",
       "format                      object\n",
       "dtype: object"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform from object to datetime\n",
    "df['birthday'] = pd.to_datetime(df['birthday'], format='%d/%m/%Y')\n",
    "sales['sale_date'] = pd.to_datetime(sales['sale_date'], format='%d/%m/%Y')\n",
    "sales['publication_date'] = pd.to_datetime(sales['publication_date'], format='%d/%m/%Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform from float to int\n",
    "df['volume_number'] = df['volume_number'].astype('Int64')\n",
    "df['year_won'] = df['year_won'].astype('Int64')\n",
    "df['year_established'] = df['year_established'].astype('Int64')\n",
    "df['marketing_spend'] = df['marketing_spend'].astype('Int64')\n",
    "df['rating_count'] = df['rating_count'].astype('Int64')\n",
    "sales['print_run_size_k'] = sales['print_run_size_k'].astype('Int64')\n",
    "sales['pages'] = sales['pages'].astype('Int64')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "book_id               0\n",
       "title                 0\n",
       "birthday              0\n",
       "country_residence     0\n",
       "hrs_writing_day       0\n",
       "volume_number         0\n",
       "series_name           0\n",
       "genre                 0\n",
       "award_name           41\n",
       "year_won             41\n",
       "pub_name              1\n",
       "pub_city              1\n",
       "pub_state             1\n",
       "pub_country           1\n",
       "year_established      1\n",
       "marketing_spend       1\n",
       "pub_id                1\n",
       "rating_mean           2\n",
       "rating_count          0\n",
       "author_name           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking for missing values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sale_date           0\n",
       "isbn                0\n",
       "sales_count         0\n",
       "book_id             0\n",
       "pub_id              0\n",
       "publication_date    0\n",
       "pages               0\n",
       "print_run_size_k    0\n",
       "price               0\n",
       "format              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# volume_number null values are the ones that don't have series\n",
    "df['volume_number'].fillna(0, inplace=True)\n",
    "\n",
    "# series_name null values are the ones that also don't have series\n",
    "df['series_name'].fillna('', inplace=True)\n",
    "\n",
    "# award_name and year_won null values are the ones that don't have awards, so let's keep them as NaN\n",
    "\n",
    "# rating_count null values are the ones that don't have ratings\n",
    "df['rating_count'].fillna(0, inplace=True)\n",
    "\n",
    "# We have one book that doesn't have a publisher\n",
    "# Let's keep the rating_mean null value as NaN to not affect the average rating\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 Check duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['book_id'].duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The df dataset has information about 58 books and the following 20 columns:\n",
      "['book_id', 'title', 'birthday', 'country_residence', 'hrs_writing_day', 'volume_number', 'series_name', 'genre', 'award_name', 'year_won', 'pub_name', 'pub_city', 'pub_state', 'pub_country', 'year_established', 'marketing_spend', 'pub_id', 'rating_mean', 'rating_count', 'author_name']\n"
     ]
    }
   ],
   "source": [
    "print(f'The df dataset has information about {df.shape[0]} books and the following {df.shape[1]} columns:\\n{list(i for i in df.columns)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sales dataset has information about 15188 sales and the following 10 columns:\n",
      "['sale_date', 'isbn', 'sales_count', 'book_id', 'pub_id', 'publication_date', 'pages', 'print_run_size_k', 'price', 'format']\n"
     ]
    }
   ],
   "source": [
    "print(f'The sales dataset has information about {sales.shape[0]} sales and the following {sales.shape[1]} columns:\\n{list(i for i in sales.columns)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can finally merge the two datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sales = pd.merge(sales, df, how='left', on=['book_id', 'pub_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sale_date</th>\n",
       "      <th>isbn</th>\n",
       "      <th>sales_count</th>\n",
       "      <th>book_id</th>\n",
       "      <th>pub_id</th>\n",
       "      <th>publication_date</th>\n",
       "      <th>pages</th>\n",
       "      <th>print_run_size_k</th>\n",
       "      <th>price</th>\n",
       "      <th>format</th>\n",
       "      <th>title</th>\n",
       "      <th>birthday</th>\n",
       "      <th>country_residence</th>\n",
       "      <th>hrs_writing_day</th>\n",
       "      <th>volume_number</th>\n",
       "      <th>series_name</th>\n",
       "      <th>genre</th>\n",
       "      <th>award_name</th>\n",
       "      <th>year_won</th>\n",
       "      <th>pub_name</th>\n",
       "      <th>pub_city</th>\n",
       "      <th>pub_state</th>\n",
       "      <th>pub_country</th>\n",
       "      <th>year_established</th>\n",
       "      <th>marketing_spend</th>\n",
       "      <th>rating_mean</th>\n",
       "      <th>rating_count</th>\n",
       "      <th>author_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2193-01-02</td>\n",
       "      <td>989-28-3705-007-2</td>\n",
       "      <td>5</td>\n",
       "      <td>HP265</td>\n",
       "      <td>CHP</td>\n",
       "      <td>2188-06-03</td>\n",
       "      <td>16</td>\n",
       "      <td>55</td>\n",
       "      <td>5.99</td>\n",
       "      <td>Board book</td>\n",
       "      <td>Heliotrope Pajamas</td>\n",
       "      <td>2141-01-31</td>\n",
       "      <td>Hong Kong</td>\n",
       "      <td>6.00</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>Childrens</td>\n",
       "      <td>Newberry Medal</td>\n",
       "      <td>2182</td>\n",
       "      <td>Cedar House Publishers</td>\n",
       "      <td>Friday Harbor</td>\n",
       "      <td>Washington</td>\n",
       "      <td>USA</td>\n",
       "      <td>1906</td>\n",
       "      <td>72000</td>\n",
       "      <td>4.54</td>\n",
       "      <td>1764</td>\n",
       "      <td>Malin Wolff</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2193-01-02</td>\n",
       "      <td>989-28-79-11297-4</td>\n",
       "      <td>3</td>\n",
       "      <td>TP887</td>\n",
       "      <td>ESP</td>\n",
       "      <td>2192-08-25</td>\n",
       "      <td>1296</td>\n",
       "      <td>30</td>\n",
       "      <td>13.46</td>\n",
       "      <td>Trade paperback</td>\n",
       "      <td>the life and times of an utterly inconsequenti...</td>\n",
       "      <td>2157-02-26</td>\n",
       "      <td>United States</td>\n",
       "      <td>5.13</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>Fiction</td>\n",
       "      <td>PEN/Faulkner Award</td>\n",
       "      <td>2192</td>\n",
       "      <td>Etaoin Shrdlu Press</td>\n",
       "      <td>Seattle</td>\n",
       "      <td>Washington</td>\n",
       "      <td>USA</td>\n",
       "      <td>1889</td>\n",
       "      <td>2320000</td>\n",
       "      <td>3.20</td>\n",
       "      <td>1369</td>\n",
       "      <td>David Beam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2193-01-02</td>\n",
       "      <td>989-28-79-18127-7</td>\n",
       "      <td>1</td>\n",
       "      <td>AY135</td>\n",
       "      <td>ESP</td>\n",
       "      <td>2179-04-24</td>\n",
       "      <td>704</td>\n",
       "      <td>15</td>\n",
       "      <td>27.99</td>\n",
       "      <td>Hardcover</td>\n",
       "      <td>And I Said Yes</td>\n",
       "      <td>2129-07-11</td>\n",
       "      <td>Norway</td>\n",
       "      <td>6.00</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>Fiction</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>Etaoin Shrdlu Press</td>\n",
       "      <td>Seattle</td>\n",
       "      <td>Washington</td>\n",
       "      <td>USA</td>\n",
       "      <td>1889</td>\n",
       "      <td>2320000</td>\n",
       "      <td>3.86</td>\n",
       "      <td>970</td>\n",
       "      <td>Elmer Komroff</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2193-01-02</td>\n",
       "      <td>989-28-79-82197-5</td>\n",
       "      <td>2</td>\n",
       "      <td>TC188</td>\n",
       "      <td>ESP</td>\n",
       "      <td>2186-12-05</td>\n",
       "      <td>469</td>\n",
       "      <td>20</td>\n",
       "      <td>12.50</td>\n",
       "      <td>Trade paperback</td>\n",
       "      <td>Thatchwork Cottage</td>\n",
       "      <td>2145-01-18</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>6.00</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>Fiction</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>Etaoin Shrdlu Press</td>\n",
       "      <td>Seattle</td>\n",
       "      <td>Washington</td>\n",
       "      <td>USA</td>\n",
       "      <td>1889</td>\n",
       "      <td>2320000</td>\n",
       "      <td>4.21</td>\n",
       "      <td>708</td>\n",
       "      <td>Burton Malamud</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2193-01-02</td>\n",
       "      <td>989-28-79-05638-4</td>\n",
       "      <td>1</td>\n",
       "      <td>TC188</td>\n",
       "      <td>ESP</td>\n",
       "      <td>2185-11-15</td>\n",
       "      <td>485</td>\n",
       "      <td>12</td>\n",
       "      <td>27.99</td>\n",
       "      <td>Hardcover</td>\n",
       "      <td>Thatchwork Cottage</td>\n",
       "      <td>2145-01-18</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>6.00</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>Fiction</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>Etaoin Shrdlu Press</td>\n",
       "      <td>Seattle</td>\n",
       "      <td>Washington</td>\n",
       "      <td>USA</td>\n",
       "      <td>1889</td>\n",
       "      <td>2320000</td>\n",
       "      <td>4.21</td>\n",
       "      <td>708</td>\n",
       "      <td>Burton Malamud</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sale_date               isbn  sales_count book_id pub_id publication_date  \\\n",
       "0 2193-01-02  989-28-3705-007-2            5   HP265    CHP       2188-06-03   \n",
       "1 2193-01-02  989-28-79-11297-4            3   TP887    ESP       2192-08-25   \n",
       "2 2193-01-02  989-28-79-18127-7            1   AY135    ESP       2179-04-24   \n",
       "3 2193-01-02  989-28-79-82197-5            2   TC188    ESP       2186-12-05   \n",
       "4 2193-01-02  989-28-79-05638-4            1   TC188    ESP       2185-11-15   \n",
       "\n",
       "   pages  print_run_size_k  price           format  \\\n",
       "0     16                55   5.99       Board book   \n",
       "1   1296                30  13.46  Trade paperback   \n",
       "2    704                15  27.99        Hardcover   \n",
       "3    469                20  12.50  Trade paperback   \n",
       "4    485                12  27.99        Hardcover   \n",
       "\n",
       "                                               title   birthday  \\\n",
       "0                                 Heliotrope Pajamas 2141-01-31   \n",
       "1  the life and times of an utterly inconsequenti... 2157-02-26   \n",
       "2                                     And I Said Yes 2129-07-11   \n",
       "3                                 Thatchwork Cottage 2145-01-18   \n",
       "4                                 Thatchwork Cottage 2145-01-18   \n",
       "\n",
       "  country_residence  hrs_writing_day  volume_number series_name      genre  \\\n",
       "0         Hong Kong             6.00              0              Childrens   \n",
       "1     United States             5.13              0                Fiction   \n",
       "2            Norway             6.00              0                Fiction   \n",
       "3            Brazil             6.00              0                Fiction   \n",
       "4            Brazil             6.00              0                Fiction   \n",
       "\n",
       "           award_name  year_won                pub_name       pub_city  \\\n",
       "0      Newberry Medal      2182  Cedar House Publishers  Friday Harbor   \n",
       "1  PEN/Faulkner Award      2192     Etaoin Shrdlu Press        Seattle   \n",
       "2                 NaN      <NA>     Etaoin Shrdlu Press        Seattle   \n",
       "3                 NaN      <NA>     Etaoin Shrdlu Press        Seattle   \n",
       "4                 NaN      <NA>     Etaoin Shrdlu Press        Seattle   \n",
       "\n",
       "    pub_state pub_country  year_established  marketing_spend  rating_mean  \\\n",
       "0  Washington         USA              1906            72000         4.54   \n",
       "1  Washington         USA              1889          2320000         3.20   \n",
       "2  Washington         USA              1889          2320000         3.86   \n",
       "3  Washington         USA              1889          2320000         4.21   \n",
       "4  Washington         USA              1889          2320000         4.21   \n",
       "\n",
       "   rating_count     author_name  \n",
       "0          1764     Malin Wolff  \n",
       "1          1369      David Beam  \n",
       "2           970   Elmer Komroff  \n",
       "3           708  Burton Malamud  \n",
       "4           708  Burton Malamud  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sales.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
